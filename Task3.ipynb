{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aba378a5",
   "metadata": {},
   "source": [
    "# ***Imports***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "4cfe098a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5ad702",
   "metadata": {},
   "source": [
    "# ***Model Definition***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "ddf8beb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CheaterCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 8, kernel_size=9, padding=4, stride=2),  # BIG kernel → global color\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(8, 16, kernel_size=5, padding=2, stride=2),  # BIG kernel + stride → even more global color\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(16, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(16*7*7, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.classifier(self.features(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b7450c",
   "metadata": {},
   "source": [
    "# ***Loading the model***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "d2609a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_model(model_class, model_path, device):\n",
    "    \"\"\"\n",
    "    Load model weights for Grad-CAM visualization.\n",
    "    \n",
    "    Args:\n",
    "        model_class: The model class to instantiate\n",
    "        model_path: Path to the .pth file\n",
    "        device: torch device (cuda/cpu)\n",
    "    \n",
    "    Returns:\n",
    "        model: Model in eval mode with requires_grad enabled for inputs\n",
    "    \"\"\"\n",
    "    model = model_class().to(device)\n",
    "    state_dict = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(state_dict)\n",
    "    \n",
    "    # Eval mode: disables dropout, batch norm\n",
    "    model.eval()\n",
    "    \n",
    "    # Keep requires_grad=True for input (needed for backprop in Grad-CAM)\n",
    "    # but freeze all model parameters\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec06223b",
   "metadata": {},
   "source": [
    "# ***Grad-CAM Functions***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "id": "0ec248de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_gradcam_hooks(model, layer_index):\n",
    "    \"\"\"\n",
    "    Register forward and backward hooks for Grad-CAM.\n",
    "    \n",
    "    Args:\n",
    "        model: Neural network model\n",
    "        layer_index: Index of the target layer in model.features\n",
    "    \n",
    "    Returns:\n",
    "        features: Dictionary to store forward activations\n",
    "        grads: Dictionary to store gradients\n",
    "        hooks: List of hook handles for cleanup\n",
    "    \"\"\"\n",
    "    features = {}\n",
    "    grads = {}\n",
    "    \n",
    "    def forward_hook(module, inp, out):\n",
    "        features[\"value\"] = out\n",
    "    \n",
    "    def backward_hook(module, grad_in, grad_out):\n",
    "        grads[\"value\"] = grad_out[0]\n",
    "    \n",
    "    target_layer = model.features[layer_index]\n",
    "    fwd_hook = target_layer.register_forward_hook(forward_hook)\n",
    "    bwd_hook = target_layer.register_full_backward_hook(backward_hook)\n",
    "    \n",
    "    return features, grads, [fwd_hook, bwd_hook]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "5fc23de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradcam(model, img, features, grads, device, \n",
    "                   image_size=(28, 28)):\n",
    "    \"\"\"\n",
    "    Compute Grad-CAM heatmap for an image.\n",
    "    \n",
    "    Args:\n",
    "        model: Neural network model\n",
    "        img: Input image tensor (B, C, H, W)\n",
    "        features: Dictionary storing forward activations (from hooks)\n",
    "        grads: Dictionary storing gradients (from hooks)\n",
    "        device: torch device\n",
    "        image_size: Size to upsample heatmap to\n",
    "    \n",
    "    Returns:\n",
    "        cam: Grad-CAM heatmap as numpy array (H, W)\n",
    "        pred_class: Predicted class index\n",
    "    \"\"\"\n",
    "    # Prepare image\n",
    "    img = img.to(device)\n",
    "    img.requires_grad = True\n",
    "    \n",
    "    # Forward pass\n",
    "    model.zero_grad()\n",
    "    logits = model(img)\n",
    "    pred_class = logits.argmax(dim=1).item()\n",
    "    \n",
    "    # Use target class if specified, otherwise use predicted class\n",
    "    # class_to_use = target_class if target_class is not None else pred_class\n",
    "    \n",
    "    # Backward pass\n",
    "    logits[0, pred_class].backward()\n",
    "    \n",
    "    # Global average pooling of gradients\n",
    "    weights = grads[\"value\"].mean(dim=(2, 3), keepdim=True)\n",
    "    \n",
    "    # Weighted sum of feature maps\n",
    "    cam = (weights * features[\"value\"]).sum(dim=1, keepdim=True)\n",
    "    \n",
    "    # Apply ReLU\n",
    "    cam = torch.relu(cam)\n",
    "    \n",
    "    # Normalize\n",
    "    cam = cam - cam.min()\n",
    "    cam = cam / (cam.max() + 1e-8)\n",
    "    \n",
    "    # Upsample to image size\n",
    "    cam = torch.nn.functional.interpolate(\n",
    "        cam, size=image_size, mode=\"bilinear\", align_corners=False\n",
    "    )\n",
    "    \n",
    "    cam = cam[0, 0].detach().cpu().numpy()\n",
    "    \n",
    "    return cam, pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "id": "88a4b94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_gradcam(img_tensor, model, device, layer_index=4):\n",
    "    \"\"\"\n",
    "    Apply Grad-CAM to a colored digit tensor.\n",
    "    \n",
    "    Args:\n",
    "        img_tensor: Image tensor (1, 3, 28, 28)\n",
    "        model: Trained neural network model\n",
    "        device: torch device\n",
    "        layer_index: Layer index for Grad-CAM\n",
    "    \n",
    "    Returns:\n",
    "        cam: Grad-CAM heatmap as numpy array\n",
    "        pred_class: Predicted class\n",
    "        hooks: List of hook handles (remember to remove them!)\n",
    "    \"\"\"\n",
    "    # Register hooks\n",
    "    features, grads, hooks = register_gradcam_hooks(model, layer_index)\n",
    "    \n",
    "    # Compute Grad-CAM\n",
    "    cam, pred_class = compute_gradcam(model, img_tensor, features, grads, device)\n",
    "    \n",
    "    return cam, pred_class, hooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88c1e9d",
   "metadata": {},
   "source": [
    "# ***Color Palette & Coloring Functions***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "id": "c263ec42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Palette with custom colors\n",
    "PALETTE = [\n",
    "    [255, 0, 0],     # 0: Red\n",
    "    [0, 255, 0],     # 1: Green\n",
    "    [0, 0, 255],     # 2: Blue\n",
    "    [255, 255, 0],   # 3: Yellow\n",
    "    [255, 0, 255],   # 4: Magenta\n",
    "    [0, 255, 255],   # 5: Cyan\n",
    "    [255, 128, 0],   # 6: Orange\n",
    "    [128, 0, 255],   # 7: Violet\n",
    "    [139, 69, 19],   # 8: Brown\n",
    "    [19, 139, 69]    # 9: Forest Green\n",
    "]\n",
    "BIAS_PROB = 0.95\n",
    "\n",
    "def select_biased_color(label, is_hard_set):\n",
    "    \"\"\"Determines color based on 95/5 rule or inversion for Hard Set.\"\"\"\n",
    "    if is_hard_set:\n",
    "        # Never use the shortcut color\n",
    "        wrong_colors = [c for i, c in enumerate(PALETTE) if i != label]\n",
    "        return random.choice(wrong_colors)\n",
    "    else:\n",
    "        # 95% shortcut, 5% random\n",
    "        if random.random() < BIAS_PROB:\n",
    "            return PALETTE[label]\n",
    "        else:\n",
    "            wrong_colors = [c for i, c in enumerate(PALETTE) if i != label]\n",
    "            return random.choice(wrong_colors)\n",
    "\n",
    "def color_foreground_stroke(grey_img, color_rgb):\n",
    "    \"\"\"\n",
    "    grey_img: (28, 28) uint8 MNIST digit\n",
    "    color_rgb: np.array([R, G, B]) in [0,255]\n",
    "\n",
    "    Returns:\n",
    "        (28, 28, 3) uint8 colored MNIST image\n",
    "    \"\"\"\n",
    "    # normalize digit\n",
    "    digit = grey_img.astype(np.float32) / 255.0\n",
    "\n",
    "    # grayscale background (uninformative)\n",
    "    bg = np.random.uniform(0.3, 0.6, (28, 28, 1))\n",
    "    bg = np.repeat(bg, 3, axis=2)\n",
    "\n",
    "    # normalize color\n",
    "    color = np.array(color_rgb, dtype=np.float32) / 255.0\n",
    "\n",
    "    # foreground stroke coloring (CRITICAL LINE)\n",
    "    img = bg * (1 - digit[..., None]) + digit[..., None] * color\n",
    "\n",
    "    # small noise to avoid pixel-perfect cues\n",
    "    img += np.random.randn(28, 28, 3) * 0.02\n",
    "    img = np.clip(img, 0, 1)\n",
    "\n",
    "    return (img * 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5db4b6",
   "metadata": {},
   "source": [
    "# ***Visualising GradCAM***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "id": "c557b708",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_gradcam(img, cam, pred_class=None, figsize=(6, 6), alpha=0.5):\n",
    "    \"\"\"\n",
    "    Visualize Grad-CAM heatmap overlaid on the original image.\n",
    "    \n",
    "    Args:\n",
    "        img: Input image tensor (B, C, H, W) or (C, H, W)\n",
    "        cam: Grad-CAM heatmap as numpy array (H, W)\n",
    "        pred_class: Predicted class for title (optional)\n",
    "        figsize: Figure size\n",
    "        alpha: Transparency of heatmap overlay\n",
    "    \"\"\"\n",
    "    # Handle batch dimension\n",
    "    if img.dim() == 4:\n",
    "        img_np = img[0].detach().cpu().permute(1, 2, 0)\n",
    "    else:\n",
    "        img_np = img.detach().cpu().permute(1, 2, 0)\n",
    "    \n",
    "    # Normalize image\n",
    "    img_np = (img_np - img_np.min()) / (img_np.max() - img_np.min())\n",
    "    \n",
    "    # Create visualization\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(img_np)\n",
    "    plt.imshow(cam, cmap=\"jet\", alpha=alpha)\n",
    "    plt.axis(\"off\")\n",
    "    \n",
    "    if pred_class is not None:\n",
    "        plt.title(f\"Grad-CAM | Predicted Class: {pred_class}\", fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effbe7e4",
   "metadata": {},
   "source": [
    "# ***Loading and Colouring funcs***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "id": "d02de7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_digit_from_dataset(digit_value, dataset_path='Class', train=False):\n",
    "    \"\"\"\n",
    "    Get a random occurrence of a specific digit from .npy files in the 'Class' folder.\n",
    "    \n",
    "    Args:\n",
    "        digit_value: The digit to find (0-9)\n",
    "        dataset_path: Path to folder containing mnist_class_0.npy, ..., mnist_class_9.npy\n",
    "        train: Included for compatibility (not used, since data is pre-split)\n",
    "    \n",
    "    Returns:\n",
    "        digit: Grayscale image as numpy array (28, 28)\n",
    "        label: The digit label\n",
    "    \"\"\"\n",
    "    filename = os.path.join(dataset_path, f'mnist_class_{digit_value}.npy')\n",
    "    \n",
    "    if not os.path.exists(filename):\n",
    "        print(f\"File {filename} not found.\")\n",
    "        return None, None\n",
    "\n",
    "    images = np.load(filename)  # Shape: (50, 28, 28)\n",
    "    idx = np.random.randint(0, images.shape[0])  # Pick random index\n",
    "    return images[idx], digit_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "b6bfaeb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_colored_digit(digit, label, is_hard_set=True):\n",
    "    \"\"\"\n",
    "    Create a colored digit image using the biased color selection.\n",
    "    \n",
    "    Args:\n",
    "        digit: Grayscale MNIST digit (28, 28) numpy array\n",
    "        label: Ground truth label (0-9)\n",
    "        is_hard_set: If True, never use the shortcut color\n",
    "    \n",
    "    Returns:\n",
    "        colored_img: Colored digit as numpy array (28, 28, 3)\n",
    "        img_tensor: PyTorch tensor ready for model input (1, 3, 28, 28)\n",
    "    \"\"\"\n",
    "    # Select color and create colored image\n",
    "    color = select_biased_color(label, is_hard_set)\n",
    "    print(f\"Colour:{color}\")\n",
    "    # color = PALETTE[7]\n",
    "    colored_img = color_foreground_stroke(digit, color)\n",
    "    \n",
    "    # Convert to tensor\n",
    "    img_tensor = torch.from_numpy(colored_img).float()\n",
    "    img_tensor = img_tensor.permute(2, 0, 1).unsqueeze(0)  # (1, 3, 28, 28)\n",
    "    \n",
    "    return colored_img, img_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0debf1cb",
   "metadata": {},
   "source": [
    "# ***Actual GradCAM Code***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "id": "a6974fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_grad_cam import GradCAM\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "\n",
    "def get_library_gradcam(input_tensor, model, target_layer):\n",
    "    \"\"\"Generates CAM using the pytorch-grad-cam library.\"\"\"\n",
    "    # Ensure model is in eval mode\n",
    "    model.eval()\n",
    "    \n",
    "    # 1. Initialize GradCAM with the library\n",
    "    # Note: target_layers must be a list\n",
    "    cam_algorithm = GradCAM(model=model, target_layers=[target_layer])\n",
    "    \n",
    "    # 2. Define target (None defaults to highest scoring class)\n",
    "    # This ensures both methods look at the same prediction\n",
    "    grayscale_cam = cam_algorithm(input_tensor=input_tensor, targets=None)\n",
    "    \n",
    "    # Take the first image in batch\n",
    "    return grayscale_cam[0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b1a823",
   "metadata": {},
   "source": [
    "# ***Usage Examples***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f94dac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "Models = \"Models\"\n",
    "model_path = os.path.join(Models, \"cheater_cnn3_24_fg\")\n",
    "\n",
    "model = load_model(CheaterCNN, model_path, device)\n",
    "\n",
    "# Get digit from dataset\n",
    "digit, label = get_digit_from_dataset(0)\n",
    "\n",
    "# Color the digit\n",
    "colored_img, img_tensor = create_colored_digit(digit, label, is_hard_set=True)\n",
    "plt.imshow(colored_img)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# Example 3: Apply Grad-CAM (make sure model is loaded)\n",
    "if 'model' in locals():\n",
    "    cam, pred_class, hooks = apply_gradcam(img_tensor, model, device, layer_index=4)\n",
    "    visualize_gradcam(img_tensor, cam, pred_class)\n",
    "\n",
    "    # Uncomment if u want comparision with actual GRAD-CAM\n",
    "    # target_layer = list(model.modules())[4] \n",
    "    # lib_cam = get_library_gradcam(img_tensor, model, target_layer)\n",
    "    # visualize_gradcam(img_tensor, lib_cam, pred_class)\n",
    "    for hook in hooks:\n",
    "        hook.remove()\n",
    "else:\n",
    "    print(\"Model not loaded. Use load_model_for_gradcam() first.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
